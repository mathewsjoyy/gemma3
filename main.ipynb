{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zyphra import ZyphraClient\n",
    "\n",
    "client = ZyphraClient(api_key=\"zsk-712f76df4ace41bc8f9bcdfde3a5f70d4ca9980fa6f75925f5285a4ae6cb0578\")\n",
    "\n",
    "# Text-to-speech\n",
    "audio_data = client.audio.speech.create(\n",
    "    text=\"Hello, world!\",\n",
    "    speaking_rate=15,\n",
    "    model=\"zonos-v0.1-transformer\"  # Default model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Record Voice to Clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "import sounddevice as sd\n",
    "\n",
    "print(sd.query_devices())\n",
    "\n",
    "# Parameters\n",
    "duration = 20 # Duration of recording in seconds\n",
    "sample_rate = 44100  # Sample rate in Hz\n",
    "\n",
    "# Record audio\n",
    "print(\"Recording...\")\n",
    "audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype=np.int16)\n",
    "sd.wait()  # Wait until recording is finished\n",
    "print(\"Recording finished.\")\n",
    "\n",
    "# Save the audio data to a WAV file\n",
    "output_file = \"output.wav\"\n",
    "write(output_file, sample_rate, audio_data)\n",
    "print(f\"Audio saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from zyphra.models.audio import EmotionWeights\n",
    "\n",
    "# Create custom emotion weights\n",
    "emotions = EmotionWeights(\n",
    "    happiness=0.6,   # Increase happiness (Default: 0.6)\n",
    "    neutral=0.6,      # Decrease neutrality (Default: 0.6)\n",
    "    sadness=0.05,     # Default: 0.05\n",
    "    disgust=0.05,     # Default: 0.05\n",
    "    fear=0.05,        # Default: 0.05\n",
    "    surprise=0.05,    # Default: 0.05\n",
    "    anger=0.05,       # Default: 0.05\n",
    "    other=0.5         # Default: 0.5\n",
    ")\n",
    "\n",
    "# Read and encode audio file\n",
    "with open(\"matt2.wav\", \"rb\") as f:\n",
    "    audio_base64 = base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "# Generate speech with cloned voice\n",
    "audio_data = client.audio.speech.create(\n",
    "    text=\"\"\"\n",
    "This day marks the death of human mathews and the birth of Matt GPT\n",
    "\n",
    "Hello everyone! Today, we’re diving into the latest AI breakthrough from Google DeepMind which is Gemma 3. We’ll explore what makes it different from Gemma 2, highlight its new key features, discuss its benefits like fine-tuning, and compare it to Gemini to see where it truly shines.\n",
    "\n",
    "So, what exactly is Gemma 3? Well, it’s the latest evolution of Google’s open-weight AI model series. It builds on the strong foundation of Gemma 2 but comes with significant upgrades in power, efficiency, and capability. Unlike Gemini, which is a closed-source AI built for broad applications, Gemma is designed to be lightweight, flexible, and fine-tunable for specific tasks. This means developers can take Gemma and shape it to their needs rather than being locked into a rigid, pre-designed system.\n",
    "Let’s take a look at the first image on the slide. This chart ranks AI models based on their Chatbot Arena Elo scores, which indicate user preference. As you can see, Gemma 3's twenty seven billion parameter model scores an impressive one thousand three hundred and thirty-eight points, placing it among the top-performing models. What makes this even more remarkable is that Gemma 3 achieves this high ranking while requiring only a single GPU, unlike other models such as the DeepSeek models, which demand significantly more computational resources. This efficiency makes Gemma 3 a highly accessible and cost-effective AI solution.\n",
    "Now, shifting to the second image on the slide, we can see how Gemma 3 27B ranks on the LMSys blind-rated leaderboard. Despite being an open-weight model, it competes closely with some of the most advanced proprietary models, including Gemini 2 and GPT-4.5 Preview. This solid ranking highlights the model’s strong real-world performance, demonstrating that open models can still provide high-quality outputs comparable to closed-source alternatives.\n",
    "\n",
    "Now, let’s talk about what’s new in Gemma 3 compared to its predecessor. First, it comes in more size variations, from 1 billion to 27 billion parameters, giving users more options depending on their computing power and application needs. One of the biggest improvements is its expanded context window, which now supports up to one hundred and twenty-eight thousand tokens. This means it can process much larger datasets, analyze longer documents, and handle complex conversations more effectively.\n",
    "Another major upgrade is its ability to handle multiple types of data. While Gemma 2 was strictly a text-based model, Gemma 3 can now analyze not just text, but also images and even short videos. This makes it incredibly versatile, especially for industries that rely on multimodal data processing. And on top of all that, it has been optimized to run efficiently on a single GPU or TPU, meaning it can deliver high performance without needing an expensive setup.\n",
    "One of the biggest advantages of Gemma 3 is its fine-tuning capability. Because it’s open-weight, developers can train it on domain-specific data to create truly customized AI solutions. This flexibility means that businesses and researchers can adapt it to their unique needs rather than relying on a one-size-fits-all model. Plus, it can be deployed locally on personal machines, reducing reliance on cloud services and giving users more control over their data.\n",
    "Whether you’re building a chatbot, automating coding tasks, or analyzing medical data, Gemma 3 allows you to tailor the AI to your specific requirements.\n",
    "\n",
    "When we compare Gemma 3 to Gemini. While both models come from Google DeepMind, they serve very different purposes. Gemini is a powerful closed-source AI model designed for general users and businesses. It offers advanced reasoning, multimodal understanding, and seamless integration with Google’s ecosystem. Gemma 3, on the other hand, is open-weight and designed for developers who need a model they can fine-tune and deploy on their own terms. While Gemini is excellent for broad applications, Gemma 3 is better suited for those who want more control over their AI models.\n",
    "Another key difference is computational cost. Gemini requires high-end cloud resources, making it more expensive to run, while Gemma 3 is optimized to run efficiently on a single GPU or TPU. As the images highlight, this is one of Gemma 3’s most compelling advantages—delivering top-tier performance without the need for massive computational power. This makes it a more accessible choice for developers and businesses that don’t have the budget for large-scale cloud computing.\n",
    "So, where does Gemma 3 really shine? It’s an excellent choice for building custom AI assistants, whether for customer service, legal research, or specialized industry support. It’s also fantastic for code generation and automation, as developers can fine-tune it to work with proprietary codebases. Medical and scientific researchers can use it to analyze large datasets, and companies focused on privacy can deploy it on local servers or edge devices where cloud-based AI isn’t an option. To sum it up, Gemma 3 takes everything great about its predecessor and makes it even better. It offers fine-tuning, efficiency, and scalability, making it a game-changer for developers, businesses, and researchers who need a flexible AI solution.\n",
    "It may not be as broadly capable as Gemini, but its open-source nature makes it one of the most adaptable AI models available today.\n",
    "\n",
    "Before we wrap up, I want to take a moment to talk about the voice you’ve been hearing throughout this presentation. This wasn’t just any voice it was generated by Zonos, an advanced AI-powered voice cloning system from Zyphra’s Maia platform.\n",
    "Zonos is capable of capturing the unique characteristics of a human voice and replicating it. It does this by analyzing vocal patterns, tone, and cadence, then synthesizing speech that sounds incredibly natural and lifelike. This technology is particularly useful for content creators, businesses, and individuals who need high-quality, customizable voiceovers without the need for traditional recording.\n",
    "The AI behind Zonos can generate speech in multiple languages allow you too adjust emotions, and even create entirely new synthetic voices. Whether it’s for narrating presentations like this one, generating audiobook content, or enhancing virtual assistants, Zonos represents a leap forward in voice synthesis technology.\n",
    "Currently there is a free plan available for Zonos, which allows you to generate up to 100 minutes of audio per month.\n",
    "Thats all for today, Thank you for listening, and I hope you found this session insightful!\n",
    "\"\"\",\n",
    "    speaker_audio=audio_base64,\n",
    "    speaking_rate=15,\n",
    "    output_path=\"output.wav\"\n",
    "    #emotion=emotions\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
